2023-05-28 03:19:54.982 669:pos-tag                DEBUG  main message
2023-05-28 03:19:54.982 675:pos-tag                WARNING device: cuda, n_gpu: 1
2023-05-28 03:19:55.667 695:pos-tag                INFO   Load Dataset
2023-05-28 03:19:55.668 699:pos-tag                INFO   Num of Class 229
2023-05-28 03:20:01.268 719:pos-tag                INFO   Finishing loading Dataset
2023-05-28 03:20:01.269 727:pos-tag                INFO   pretrained the encoder
2023-05-28 03:20:04.893 755:pos-tag                INFO   Probimg Model Parameters 176101
2023-05-28 03:20:04.894 756:pos-tag                INFO   Training/evaluation parameters Namespace(adam_epsilon=1e-08, config_name='Salesforce/codet5-base', data_folder='../datasets/poj-104/postag/', dataset='postag', debug=False, device=device(type='cuda'), do_eval=True, do_random=False, do_test=True, do_train=True, epochs=5, eval_batch_size=32, evaluate_during_training=False, gradient_accumulation_steps=1, graph_type='ast', layer=5, learning_rate=0.001, max_code_length=512, max_grad_norm=1.0, max_steps=-1, model_name='codet5', model_name_or_path='Salesforce/codet5-base', n_gpu=1, output_dir='./pos_res_poj/plm/saved_codet5models/4/layer_5', posratio=0.5, seed=886, token_config='Salesforce/codet5-base', train_batch_size=64, warmup_steps=0, weight_decay=0.0)
2023-05-28 03:20:04.895 178:pos-tag                INFO   save steps 1
2023-05-28 03:20:06.809 217:pos-tag                INFO   ***** Running training *****
2023-05-28 03:20:06.810 218:pos-tag                INFO     Num examples = 1200
2023-05-28 03:20:06.810 219:pos-tag                INFO     Num Epochs = 5
2023-05-28 03:20:06.810 220:pos-tag                INFO     Instantaneous batch size per GPU = 64
2023-05-28 03:20:06.810 224:pos-tag                INFO     Total train batch size = 64
2023-05-28 03:20:06.810 228:pos-tag                INFO     Gradient Accumulation steps = 1
2023-05-28 03:20:06.810 231:pos-tag                INFO     Total optimization steps = 95
