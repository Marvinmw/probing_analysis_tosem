2023-05-27 16:58:11.584 669:pos-tag                DEBUG  main message
2023-05-27 16:58:11.584 675:pos-tag                WARNING device: cuda, n_gpu: 1
2023-05-27 16:58:12.236 695:pos-tag                INFO   Load Dataset
2023-05-27 16:58:12.237 699:pos-tag                INFO   Num of Class 229
2023-05-27 16:58:17.710 719:pos-tag                INFO   Finishing loading Dataset
2023-05-27 16:58:17.710 727:pos-tag                INFO   pretrained the encoder
2023-05-27 16:58:21.365 755:pos-tag                INFO   Probimg Model Parameters 176101
2023-05-27 16:58:21.365 756:pos-tag                INFO   Training/evaluation parameters Namespace(adam_epsilon=1e-08, config_name='Salesforce/codet5-base', data_folder='../datasets/poj-104/postag/', dataset='postag', debug=False, device=device(type='cuda'), do_eval=True, do_random=False, do_test=True, do_train=True, epochs=5, eval_batch_size=32, evaluate_during_training=False, gradient_accumulation_steps=1, graph_type='ast', layer=10, learning_rate=0.001, max_code_length=512, max_grad_norm=1.0, max_steps=-1, model_name='codet5', model_name_or_path='Salesforce/codet5-base', n_gpu=1, output_dir='./pos_res_poj/plm/saved_codet5models/3/layer_10', posratio=0.5, seed=358, token_config='Salesforce/codet5-base', train_batch_size=64, warmup_steps=0, weight_decay=0.0)
2023-05-27 16:58:21.366 178:pos-tag                INFO   save steps 1
2023-05-27 16:58:23.360 217:pos-tag                INFO   ***** Running training *****
2023-05-27 16:58:23.360 218:pos-tag                INFO     Num examples = 1200
2023-05-27 16:58:23.361 219:pos-tag                INFO     Num Epochs = 5
2023-05-27 16:58:23.361 220:pos-tag                INFO     Instantaneous batch size per GPU = 64
2023-05-27 16:58:23.361 224:pos-tag                INFO     Total train batch size = 64
2023-05-27 16:58:23.361 228:pos-tag                INFO     Gradient Accumulation steps = 1
2023-05-27 16:58:23.361 231:pos-tag                INFO     Total optimization steps = 95
