2023-05-27 19:11:19.244 669:pos-tag                DEBUG  main message
2023-05-27 19:11:19.244 675:pos-tag                WARNING device: cuda, n_gpu: 1
2023-05-27 19:11:19.933 695:pos-tag                INFO   Load Dataset
2023-05-27 19:11:19.934 699:pos-tag                INFO   Num of Class 229
2023-05-27 19:11:25.468 719:pos-tag                INFO   Finishing loading Dataset
2023-05-27 19:11:25.469 727:pos-tag                INFO   pretrained the encoder
2023-05-27 19:11:29.131 755:pos-tag                INFO   Probimg Model Parameters 176101
2023-05-27 19:11:29.131 756:pos-tag                INFO   Training/evaluation parameters Namespace(adam_epsilon=1e-08, config_name='Salesforce/codet5-base', data_folder='../datasets/poj-104/postag/', dataset='postag', debug=False, device=device(type='cuda'), do_eval=True, do_random=False, do_test=True, do_train=True, epochs=5, eval_batch_size=32, evaluate_during_training=False, gradient_accumulation_steps=1, graph_type='ast', layer=6, learning_rate=0.001, max_code_length=512, max_grad_norm=1.0, max_steps=-1, model_name='codet5', model_name_or_path='Salesforce/codet5-base', n_gpu=1, output_dir='./pos_res_poj/plm/saved_codet5models/3/layer_6', posratio=0.5, seed=358, token_config='Salesforce/codet5-base', train_batch_size=64, warmup_steps=0, weight_decay=0.0)
2023-05-27 19:11:29.132 178:pos-tag                INFO   save steps 1
2023-05-27 19:11:31.117 217:pos-tag                INFO   ***** Running training *****
2023-05-27 19:11:31.118 218:pos-tag                INFO     Num examples = 1200
2023-05-27 19:11:31.118 219:pos-tag                INFO     Num Epochs = 5
2023-05-27 19:11:31.118 220:pos-tag                INFO     Instantaneous batch size per GPU = 64
2023-05-27 19:11:31.118 224:pos-tag                INFO     Total train batch size = 64
2023-05-27 19:11:31.118 228:pos-tag                INFO     Gradient Accumulation steps = 1
2023-05-27 19:11:31.119 231:pos-tag                INFO     Total optimization steps = 95
