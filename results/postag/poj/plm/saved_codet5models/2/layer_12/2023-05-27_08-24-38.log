2023-05-27 08:24:38.687 669:pos-tag                DEBUG  main message
2023-05-27 08:24:38.688 675:pos-tag                WARNING device: cuda, n_gpu: 1
2023-05-27 08:24:39.336 695:pos-tag                INFO   Load Dataset
2023-05-27 08:24:39.337 699:pos-tag                INFO   Num of Class 229
2023-05-27 08:24:45.241 719:pos-tag                INFO   Finishing loading Dataset
2023-05-27 08:24:45.242 727:pos-tag                INFO   pretrained the encoder
2023-05-27 08:24:49.039 755:pos-tag                INFO   Probimg Model Parameters 176101
2023-05-27 08:24:49.039 756:pos-tag                INFO   Training/evaluation parameters Namespace(adam_epsilon=1e-08, config_name='Salesforce/codet5-base', data_folder='../datasets/poj-104/postag/', dataset='postag', debug=False, device=device(type='cuda'), do_eval=True, do_random=False, do_test=True, do_train=True, epochs=5, eval_batch_size=32, evaluate_during_training=False, gradient_accumulation_steps=1, graph_type='ast', layer=12, learning_rate=0.001, max_code_length=512, max_grad_norm=1.0, max_steps=-1, model_name='codet5', model_name_or_path='Salesforce/codet5-base', n_gpu=1, output_dir='./pos_res_poj/plm/saved_codet5models/2/layer_12', posratio=0.5, seed=317, token_config='Salesforce/codet5-base', train_batch_size=64, warmup_steps=0, weight_decay=0.0)
2023-05-27 08:24:49.040 178:pos-tag                INFO   save steps 1
2023-05-27 08:24:50.719 217:pos-tag                INFO   ***** Running training *****
2023-05-27 08:24:50.720 218:pos-tag                INFO     Num examples = 1200
2023-05-27 08:24:50.720 219:pos-tag                INFO     Num Epochs = 5
2023-05-27 08:24:50.720 220:pos-tag                INFO     Instantaneous batch size per GPU = 64
2023-05-27 08:24:50.720 224:pos-tag                INFO     Total train batch size = 64
2023-05-27 08:24:50.720 228:pos-tag                INFO     Gradient Accumulation steps = 1
2023-05-27 08:24:50.720 231:pos-tag                INFO     Total optimization steps = 95
