2023-05-27 09:00:54.149 669:pos-tag                DEBUG  main message
2023-05-27 09:00:54.149 675:pos-tag                WARNING device: cuda, n_gpu: 1
2023-05-27 09:00:54.916 695:pos-tag                INFO   Load Dataset
2023-05-27 09:00:54.917 699:pos-tag                INFO   Num of Class 229
2023-05-27 09:01:05.201 719:pos-tag                INFO   Finishing loading Dataset
2023-05-27 09:01:05.203 727:pos-tag                INFO   pretrained the encoder
2023-05-27 09:01:14.547 755:pos-tag                INFO   Probimg Model Parameters 176101
2023-05-27 09:01:14.548 756:pos-tag                INFO   Training/evaluation parameters Namespace(adam_epsilon=1e-08, config_name='Salesforce/codet5-base', data_folder='../datasets/poj-104/postag/', dataset='postag', debug=False, device=device(type='cuda'), do_eval=True, do_random=False, do_test=True, do_train=True, epochs=5, eval_batch_size=32, evaluate_during_training=False, gradient_accumulation_steps=1, graph_type='ast', layer=11, learning_rate=0.001, max_code_length=512, max_grad_norm=1.0, max_steps=-1, model_name='codet5', model_name_or_path='Salesforce/codet5-base', n_gpu=1, output_dir='./pos_res_poj/plm/saved_codet5models/2/layer_11', posratio=0.5, seed=317, token_config='Salesforce/codet5-base', train_batch_size=64, warmup_steps=0, weight_decay=0.0)
2023-05-27 09:01:14.549 178:pos-tag                INFO   save steps 1
2023-05-27 09:01:17.985 217:pos-tag                INFO   ***** Running training *****
2023-05-27 09:01:17.986 218:pos-tag                INFO     Num examples = 1200
2023-05-27 09:01:17.987 219:pos-tag                INFO     Num Epochs = 5
2023-05-27 09:01:17.987 220:pos-tag                INFO     Instantaneous batch size per GPU = 64
2023-05-27 09:01:17.987 224:pos-tag                INFO     Total train batch size = 64
2023-05-27 09:01:17.988 228:pos-tag                INFO     Gradient Accumulation steps = 1
2023-05-27 09:01:17.988 231:pos-tag                INFO     Total optimization steps = 95
